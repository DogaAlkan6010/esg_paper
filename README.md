# ESG Paper Data Processing Pipeline

This repository contains a modular, extensible pipeline for processing ESG (Environmental, Social, Governance) data from multiple providers and linking it to financial databases via GVKEY identifiers.

## üèóÔ∏è Project Structure

```
esg_paper/
‚îú‚îÄ‚îÄ README.md                    # This file
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îú‚îÄ‚îÄ data/                       # Data directories (created automatically)
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ esg_ratings/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ refinitiv/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ msci/
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ       ‚îú‚îÄ‚îÄ security_master/
‚îÇ       ‚îî‚îÄ‚îÄ id_mappings/
‚îî‚îÄ‚îÄ src/                        # Source code
    ‚îî‚îÄ‚îÄ data_preparation/
        ‚îú‚îÄ‚îÄ README.md           # Detailed module documentation
        ‚îú‚îÄ‚îÄ run_mappers.py      # Main orchestration script
        ‚îú‚îÄ‚îÄ example_usage.py    # Usage examples
        ‚îî‚îÄ‚îÄ esg_mappers/        # Mapper implementations
            ‚îú‚îÄ‚îÄ __init__.py
            ‚îú‚îÄ‚îÄ base_mapper.py          # Abstract base class
            ‚îú‚îÄ‚îÄ refinitiv_mapper.py     # Refinitiv implementation
            ‚îî‚îÄ‚îÄ msci_mapper.py          # MSCI implementation
```

## üöÄ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Prepare Your Data

- Place your security master file at: `data/processed/security_master/security_master_segments.csv`
- Place ESG data files:
  - Refinitiv: `data/raw/esg_ratings/refinitiv/Refinitiv_Wharton_FULL_DB.csv`
  - MSCI: Excel files in `data/raw/esg_ratings/msci/`

### 3. Run the Pipeline

```bash
cd src/data_preparation
python run_mappers.py
```

## üéØ Key Features

### ‚úÖ **Modular & Extensible**
- Abstract base class handles common functionality
- Easy to add new ESG data providers
- DRY (Don't Repeat Yourself) architecture

### ‚úÖ **Robust Matching Logic**
- Multi-step identifier matching (CUSIP6, ISIN, Ticker)
- Quality scoring system for match prioritization
- Handles various data formats and encodings

### ‚úÖ **Production Ready**
- Comprehensive error handling
- Progress tracking with timestamps
- Detailed logging and output files

### ‚úÖ **Multiple Output Formats**
- Yearly match details
- Entity-level crosswalks
- Consolidated cross-provider mapping

## üìä Supported Providers

| Provider | Identifier | Input Format | Status |
|----------|------------|--------------|--------|
| **Refinitiv** | OrgPermID | CSV | ‚úÖ Implemented |
| **MSCI** | IssuerID | Excel | ‚úÖ Implemented |
| Sustainalytics | Entity ID | CSV | üîÑ Future |
| S&P Global | Entity ID | CSV | üîÑ Future |

## üõ†Ô∏è Usage Examples

### Individual Mapper Usage

```python
from esg_mappers.refinitiv_mapper import RefinitivMapper

# Initialize mapper
mapper = RefinitivMapper(
    security_master_path="path/to/security_master.csv",
    output_dir="./processed/id_mappings"
)

# Run mapping
matches, crosswalk = mapper.run("path/to/refinitiv_data.csv")

print(f"Matched {len(matches):,} entity-year pairs")
print(f"Mapped {len(crosswalk):,} unique entities")
```

### Batch Processing

```python
cd src/data_preparation
python run_mappers.py  # Processes all enabled providers
```

### Analysis & Results

```python
python example_usage.py  # Runs examples and shows analysis
```

## üìà Output Files

The pipeline generates three types of output files:

### 1. **Yearly Matches** (`{provider}_{entity_id}_year_match.csv`)
Detailed year-by-year matching results with:
- Match source (CUSIP6, ISIN, Ticker)
- Quality scores and overlap calculations
- Security characteristics and exchange information

### 2. **Entity Crosswalk** (`{provider}_{entity_id}_to_gvkey.csv`)
One record per entity with:
- Best GVKEY mapping based on aggregated scores
- Coverage statistics (years covered, first/last seen)
- Primary PERMNO assignments

### 3. **Consolidated Mapping** (`consolidated_esg_to_gvkey.csv`)
Combined mapping across all providers for cross-provider analysis.

## üîß Adding New Providers

Adding a new ESG data provider is straightforward:

1. **Create a new mapper class**:
```python
from esg_mappers.base_mapper import BaseESGMapper

class NewProviderMapper(BaseESGMapper):
    def __init__(self, ...):
        super().__init__(...)
        self.provider_name = "new_provider"
        self.entity_id_col = "entity_id"
    
    def load_provider_data(self, data_path: str) -> pd.DataFrame:
        # Load and clean your data
        pass
    
    def extract_identifiers(self, df: pd.DataFrame) -> pd.DataFrame:
        # Extract CUSIP6, ISIN, ticker symbols
        pass
    
    def perform_matching(self, provider_data, security_master) -> pd.DataFrame:
        # Use inherited methods like match_by_cusip6()
        pass
```

2. **Register the mapper**:
```python
# In run_mappers.py
MAPPER_REGISTRY["new_provider"] = NewProviderMapper

DATA_SOURCES["new_provider"] = {
    "path": "./data/raw/esg_ratings/new_provider/",
    "enabled": True
}
```

## üß™ Testing

The pipeline includes example usage scripts that demonstrate functionality:

```bash
cd src/data_preparation
python example_usage.py
```

## üìã Requirements

- **Python**: 3.8+
- **Core Libraries**: pandas, numpy
- **Excel Support**: python-calamine, openpyxl
- **Memory**: Varies by dataset size (typically 1-4GB RAM)

## üóÇÔ∏è Data Setup

The pipeline requires several data files. You have **two options** for the security master:

### **Option 1: Auto-build from Raw CRSP (Recommended)**
Place your raw CRSP files here - the pipeline will build the security master automatically:
```
data/raw/crsp/CRSP_STOCK_EVENTS_HIST_DESC_INF_FULL_DB.csv
data/raw/crsp/CRSP_COMPUSTAT_LINKING_TABLE_FULL_DATABASE.csv
```

### **Option 2: Use Pre-built Security Master**
If you already have a security master file:
```
data/processed/security_master/security_master_segments.csv
```

### **ESG Data Files (Required)**
```
data/raw/esg_ratings/refinitiv/Refinitiv_Wharton_FULL_DB.csv
data/raw/esg_ratings/msci/*.xlsx
```

**üìñ For detailed setup instructions, see [SETUP_GUIDE.md](SETUP_GUIDE.md)**

**‚úÖ Check your setup:**
```bash
python3 check_data_files.py
```

## ü§ù Contributing

The modular design makes it easy to contribute:

1. **New Providers**: Follow the template in the "Adding New Providers" section
2. **Base Functionality**: Enhance the `BaseESGMapper` class for shared improvements
3. **Output Formats**: Add new analysis functions to the main runner script

## üìÑ Data Requirements

### Security Master File
- Columns: `permno`, `gvkey`, `namedt`, `nameendt`, `ncusip6`, `ticker`, etc.
- Format: CSV with CRSP-Compustat linking data

### ESG Provider Data
- **Refinitiv**: CSV with `orgpermid`, `year`, `cusip`, `isin`, `ticker`, `comname`
- **MSCI**: Excel files with `ISSUERID`, `YEAR`, `ISSUER_CUSIP`, `ISSUER_ISIN`, etc.

## üéØ Design Principles

1. **Separation of Concerns**: Each mapper handles only its provider's specifics
2. **Reusability**: Common logic is shared via inheritance
3. **Extensibility**: New providers require minimal code changes
4. **Robustness**: Comprehensive error handling and data validation
5. **Transparency**: Detailed progress reporting and match quality scoring

---

*Built for academic research with a focus on modularity, reproducibility, and extensibility.*
